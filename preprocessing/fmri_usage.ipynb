{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THINGS-fMRI usage notes (Modified Version)\n",
    "\n",
    "### THINGS-fMRI1 b-value extraction notebook\n",
    "\n",
    "Part of codes are grabbing from the THINGS-data repository: [link](https://github.com/ViCCo-Group/THINGS-data/blob/main/MRI/notebooks/fmri_usage.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a detailed description of the data and the procedures that generated it, see [the THINGS-data preprint](https://doi.org/10.1101/2022.07.22.501123)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn.masking import apply_mask, unmask\n",
    "from nilearn.plotting import plot_epi, plot_stat_map\n",
    "from nilearn.image import load_img, index_img, iter_img\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes you've downloaded the THINGS-fMRI data to this directory\n",
    "basedir = '/Users/yilewang/Desktop'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single trial responses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single trial responses are arguably the easiest way to analyze the THINGS-fMRI data. They contains the magnitude of the fMRI response to each stimulus in each voxel with a single number. The single trial responses are provided in two formats: a) In table format, b) in volumetric format."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the fMRI response data, the table format contains metadata about each voxel (such as noise ceilings, pRF parameters, regions of interest) and about the stimulus (such as image file name, trial type, run and session). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes you downloaded the single trial responses in table format to this directory \n",
    "betas_csv_dir = pjoin(basedir, 'betas_csv')\n",
    "\n",
    "# and that you're interested in the data for the first subject\n",
    "sub = '01'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sub-{subject}_ResponseData.h5` files contain the actual single trial responses. Rows are voxels, columns are trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pjoin(betas_csv_dir, f'sub-{sub}_ResponseData.h5')\n",
    "responses = pd.read_hdf(data_file)  # this may take a minute\n",
    "print('Single trial response data')\n",
    "responses.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sub-{subject}_VoxelMetadata.csv` files contain additional information about each voxel, such as membership to ROIs, reliability measures, and noise ceilings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_f = pjoin(betas_csv_dir, f'sub-{sub}_VoxelMetadata.csv')\n",
    "voxdata = pd.read_csv(vox_f)\n",
    "voxdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('available voxel metadata:\\n', voxdata.columns.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voxel indices can be used to reconstruct a volume, e.g. for visualizing results obtained from the single trial responses. Alternatively, the brain mask can be used for that purpose (see below). Membership of each voxel to the available ROIs is dummy coded, e.g. in `voxdata[\"V1\"]` or `voxdata[\"rFFA\"]`. The population receptive field parameters are encoded in the following columns: `prf-eccentricity`, `prf-polarangle`, `prf-size`, and `prf-rsquared`. Finally, different reliability estimates are available in the columns: `nc_testset`, `nc_singletrial`, `splithalf_uncorrected`, and `splithalf_corrected`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sub-{subject}_StimulusMetadata.csv` files contain information about the file name of the image shown in each trial, which run and session a given trial occured in, and the trial_type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stimulus metadata\n",
    "stim_f = pjoin(betas_csv_dir, f'sub-{sub}_StimulusMetadata.csv')\n",
    "stimdata = pd.read_csv(stim_f)\n",
    "stimdata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸš¨ **Trial types**\n",
    ">\n",
    "> The THINGS-fMRI experiment presented participants with three different trial types:\n",
    "> - `train`: Participants passively viewed an object image.\n",
    "> - `test`: Same as train, but these trials belonged to a set of 200 images which were presented in each session. It's main purpose is to allow for estimating the reliability of the single trial responses in a given voxel.\n",
    "> - `catch`: Participants saw a non-object image and responded with a button press. This was included to ensure participants were engaged throughout the experiment.\n",
    ">\n",
    "> Note: Catch trials are excluded from the single trial responses in table format as they are likely not of interest for most applications. However, catch trials are included in the volumetric format in order to make it possible to account for them in analyses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single trial responses are also provided in volume format which preserves the spatial structure of the data. The data is broken up into runs and sessions, similar to the raw data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directory containing the single trial responses in volume form\n",
    "betas_vol_dir = pjoin(basedir, 'betas_vol', f'sub-{sub}')\n",
    "# show directory content\n",
    "files = glob.glob(pjoin(betas_vol_dir, '*', '*'))\n",
    "files = [f.replace(basedir, '') for f in files]\n",
    "print('\\n'.join(files[:10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `...betas.nii.gz` files are 3D+time nifti images where the time dimension corresponds to  trials. The `...conditions.tsv` contain the file names of object images for each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load responses for example run\n",
    "betas_f = pjoin(betas_vol_dir, 'ses-things01', f'sub-{sub}_ses-things01_run-01_betas.nii.gz')\n",
    "betas_example = load_img(betas_f)\n",
    "\n",
    "# and plot the volume of the 3rd trial\n",
    "betas_example = index_img(betas_example, 2)\n",
    "g = plot_stat_map(\n",
    "    betas_example, bg_img=None, annotate=False, cmap='twilight', vmax=.4,  draw_cross=False, \n",
    ")\n",
    "g.title('Example: Volumetric single trial response (trial# 3)', bgcolor='white', color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trial conditions\n",
    "# Note that the volumetric single trial responses include catch trials\n",
    "conds_tsv = pjoin(betas_vol_dir, 'ses-things01', f'sub-{sub}_ses-things01_run-01_conditions.tsv')\n",
    "conds = pd.read_csv(conds_tsv, sep='\\t').drop(columns='Unnamed: 0')\n",
    "print('Content of \"...conditions.tsv\"')\n",
    "conds.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain masks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brain masks indicate wether a given voxel is located in the brain or not (`1: brain`, `0: not brain`). They can be used e.g. to create a nifti volume from the results you obtained from the single trial responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Say you have analyzed the single trial responses in table format have produced these results\n",
    "# These results are an array of n elements, where n is the number of voxels within the brain.\n",
    "results = np.random.randn(responses.shape[0])\n",
    "loinds = voxdata['lLOC'].astype(bool) # pretend we found activity in LOC\n",
    "results[loinds] += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can easily use nilearn's masking functions to transform them \n",
    "# to an image object and save it as a nifti file\n",
    "\n",
    "# This is the provided brain mask\n",
    "bmask_dir = pjoin(basedir, 'brainmasks')\n",
    "bmask_f = pjoin(bmask_dir, f'sub-{sub}_space-T1w_brainmask.nii.gz')\n",
    "\n",
    "# use the brain mask to turn your results array into a 3D image\n",
    "results_img = unmask(results, bmask_f)\n",
    "# plot the image to verify\n",
    "g = plot_stat_map(results_img, bg_img=None, cmap='twilight', draw_cross=False, annotate=False)\n",
    "# g.add_contours(bmask_f)\n",
    "g.title('Example: Reconstructing volume from array-like data', bgcolor='white', color='black')\n",
    "# and save it as an nifti file\n",
    "results_img.to_filename('results.nii.gz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸš¨ **Co-registration and volumetric space**\n",
    ">\n",
    "> The THINGS-fMRI data was preprocessed with [fmriprep](https://fmriprep.org/en/stable/), which includes co-registration of all functional images to a high-resolution anatomical MRI image. In other words, all functional data for a given subject (including the brain masks aind regions of interest) was transformed into a common \"space\", meaning that a given voxel always points to the same location in the brain - with some level of imperfection.\n",
    "> Of course, it's possible to analyze the data in a different space (e.g. MNI) by downloading the raw data and preprocessing it according to your needs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cortical flat maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide flat maps for each subject for visualizing results on a flat representation of the cortical surface with `pycortex`. Provided that you saved your results as a nifti file in the same space that the volumetric data was in, you can use the flat maps and transformation matrices we prepared. Before you can get started, check out the [pycortex documentation](https://gallantlab.github.io/pycortex/) for an explanation on how to set up your installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results we prepared above as a volume object in pycortex\n",
    "results_data = np.swapaxes(load_img('results.nii.gz').get_fdata(), 0, -1)\n",
    "vol_data = cortex.Volume(results_data, 'S1', 'align_auto', cmap='twilight', vmin=-6, vmax=6)\n",
    "# plot with pycortex\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "cortex.quickshow(\n",
    "    vol_data, pixelwise=True, nanmean=True, colorbar_location='left', with_rois=False, fig=fig,\n",
    ")\n",
    "plt.title(f'Example: Visualizing results on flat maps')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('pycortex_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0353db5c40e4acea9704ff3791d606e9ce74d1fd9ef57063d56e39bfb4a5910f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
